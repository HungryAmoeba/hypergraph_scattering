{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dhg import Hypergraph\n",
    "from hypgs.models.hsn_pyg import HSN\n",
    "from hypgs.utils.data import HGDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch.utils.data import random_split\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = TUDataset(root='../data/', name=\"MUTAG\", use_node_attr=True)\n",
    "to_hg_func = lambda g: Hypergraph.from_graph_kHop(g, 1)\n",
    "dataset = HGDataset(original_dataset, to_hg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'dataset' is your PyTorch Dataset\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "val_size = int(0.15 * dataset_size)\n",
    "test_size = dataset_size - (train_size + val_size)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HSN(in_channels=7, \n",
    "              hidden_channels=16,\n",
    "              out_channels = 2, \n",
    "              trainable_laziness = False,\n",
    "              trainable_scales = False, \n",
    "              activation = 'modulus', \n",
    "              fixed_weights=True, \n",
    "              layout=['hsm'], \n",
    "              normalize='right', \n",
    "              pooling='max',\n",
    "              task='classification',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.1 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: lightning_logs/my_model\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | layers      | ModuleList         | 102   \n",
      "1 | batch_norm  | BatchNorm          | 84    \n",
      "2 | fc1         | Linear             | 903   \n",
      "3 | fc2         | Linear             | 44    \n",
      "4 | relu        | ReLU               | 0     \n",
      "5 | batch_norm1 | BatchNorm1d        | 42    \n",
      "6 | mlp         | Sequential         | 989   \n",
      "7 | accuracy    | MulticlassAccuracy | 0     \n",
      "8 | auroc       | MulticlassAUROC    | 0     \n",
      "---------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4757c204a24e1b995c12b758af99bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 516. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0832a288f44d6c8faaf307604461b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/torch_geometric/warnings.py:17: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 578. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 563. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 580. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 591. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c9522cd26d4a6bbd8906abd730fcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.684\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 576. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 551. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 575. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 595. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 53. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3701bc6612841a997ba9e64d17e58b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.684\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 552. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 608. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 610. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 526. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 54. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7e4eb24f52439aaf0edcff93b599e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.679\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 573. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 584. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 565. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 48. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c9cff24242492ea88e97bb71210b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 574. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 557. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 604. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 42. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a9c6794ad3477fb31d1611fb9e4f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 593. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 559. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 55. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0facbaee6b334a5a9cf91e7c00a477c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.662\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 600. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 564. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 577. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 555. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ff69b3074e49dab3b470a315a13994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.649\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 571. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 579. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 582. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 41. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd42a2cb485452999e1d5a5358c2390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.639\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 566. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 592. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 553. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 47. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4d25ca690c407e814b41251eec2358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 556. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 572. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 63. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49e025d24ad426aa70d8d529d7a4bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 558. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 605. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 45. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899995e26157476995a3633ed63dd94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 554. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 594. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c7d710c0504bc9bfcf5dab66ad8e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 560. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 618. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 567. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99481c7630514291824fe5159683cf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 548. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 569. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d677c82cce46698a4eb63e58debc20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 607. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 536. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 602. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 57. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c65f1c45d0b473ea5fa092a87a88b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 634. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 561. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 514. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 596. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04a57e4e6394b2e9ccf39a742ef4003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 562. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 601. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0d42b0b7914d97b17be47149cd7230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 52. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461c667afef34100a213a9f2cc15161b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.639. Signaling Trainer to stop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7fda6631b64aab817f664cf410ab0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.7586206793785095\n",
      "     test_auc_epoch          0.773809552192688\n",
      "     test_loss_epoch        1.6698592901229858\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumry2023_cqx3/.conda/envs/hyper/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 505. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 1.6698592901229858,\n",
       "  'test_acc_epoch': 0.7586206793785095,\n",
       "  'test_auc_epoch': 0.773809552192688}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Early stopping callback based on validation loss\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, verbose=True, mode='min')\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"my_model\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,  # Adjust as necessary\n",
    "    logger=logger,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n",
    "# Assuming you have defined train_loader and val_loader\n",
    "trainer.fit(model, train_loader, val_loader)  # Corrected argument names\n",
    "# Test the model\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.15.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# to see the logs run\n",
    "!tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].x.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyper",
   "language": "python",
   "name": "hyper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
