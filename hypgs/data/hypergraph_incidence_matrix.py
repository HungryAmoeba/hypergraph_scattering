# -*- coding: utf-8 -*-
"""Hypergraph Incidence Matrix

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1li_XMhTEB_a5db6Q3O8vrPA01mu14f-l

# Incidence Matrix
The goal of this program is to form the incidence matrix for a given hypergraph

If you need to download hypergraph represented data, use the following github
* https://github.com/malllabiisc/HyperGCN

To be able to use the following data representation, you will need to install the following packages
* `configargparse`
* `torch_geometric`
"""

!pip install configargparse
!pip install torch_geometric

"""# Import Packages
Before importing the following packages, make sure to set your directory in the correct place if you are using the hypergraph data from github.
"""

from dataFolder import data # from github above, comment out if you don't need
import configargparse
from configFolder import config # from github above, comment out if you don't need
import torch
import torch_geometric
import numpy as np
import os
from itertools import chain

"""# Load in Data in Hypergraph Representation
##### This is the source code from the NeurIPS 2019 paper: **HyperGCN: A New Method of Training Graph Convolutional Networks on Hypergraphs**
"""

args = config.parse()

# seed
torch.manual_seed(args.seed)
np.random.seed(args.seed)

# gpu, seed
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = str(args.gpu)
os.environ['PYTHONHASHSEED'] = str(args.seed)

# load data
dataset, train_set, test_set = data.load(args)

"""When we load in the coauthorship dataset, it is in the form of a dicitonary. The keys of the dataset are the following
* `dataset.keys() = dict_keys(['hypergraph', 'features', 'labels', 'n'])`
  *  `dataset['hypergraph']` is a dicitonary in which its keys are author names and each keys value is a list of hyperedges that author is in
  * `dataset['features']` is a matrix where each row is a bag of words. In other words, each row is full of zeros or ones representing if a given word is present.
  * `dataset['labels']` is a matrix where each row is a one-hot vector where the one is located depending on what the topic of a paper is
  * `dataset['n']` is the number of hyperedges

The following two functions complete the following tasks
* `str_to_int(hedge_dict)` takes a dictionary as input and converts string key values to integers
* `get_incidence(hedge_dict, num_hedge)` takes a dictonary and an integer as input values and returns the respective incidence matrix of size $n$ x $m$ where $n$ is the number of nodes, and $m$ is the number of hyperedges
"""

def str_to_int(hedge_dict):
  '''The goal of this function is to replace author names
    or string key values with integers so we can build a
    matrix'''

  hyperedges = hedge_dict.values() # extract the string
  hyper_index = list(range(len(hyperedges))) # list of integers with length of the length of input dict
  int_dict = dict(zip(hyper_index, hyperedges)) # create a dictionary to replace string with integers

  for tup in enumerate(hyperedges):
    i, val = tup
    int_dict[i] = val

  return int_dict

def get_incidence(hedge_dict, num_hedge):
  '''The goal of this function is to transform a dictionary to
     a incidence matrix for a given hyperedge dataset'''

  num_nodes = len(hedge_dict)
  incidence = np.zeros(shape = (num_nodes, num_hedge))

  for val in hedge_dict.items():
    node, hedge = val

    for idx in hedge:
      if incidence[node][idx - 1] == 0:
        incidence[node][idx - 1] = 1

  return incidence

hedge_dict = str_to_int(dataset['hypergraph'])
final_inc = get_incidence(hedge_dict = hedge_dict, num_hedge = dataset['n'])
final_inc

final_inc.shape